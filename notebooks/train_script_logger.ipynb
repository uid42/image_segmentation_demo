{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.basic_train import LearnerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.callbacks.general_sched import *\n",
    "from fastai.callback import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from IPython.core import debugger as idb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from FLAI.detect_symbol.exp import optimizer\n",
    "from FLAI.detect_symbol.exp import tensorboard_callback\n",
    "from FLAI.detect_symbol.exp import scheduling_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from exp import resnet_unet\n",
    "from exp import loss_metrics\n",
    "from exp import databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from torch.nn import Sequential, ModuleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.basic_train import Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.torch_core import bn_types,bias_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os,shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.callbacks import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.callbacks.tracker import SaveModelCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def txt_write(fh, i, opt, lr, path, csv_fname):\n",
    "    fh.write('===================================\\n')\n",
    "    fh.write(f'run_{i}\\n')\n",
    "    fh.write('-----------------------------------\\n')\n",
    "    fh.write(f'--opt_func: {opt}\\n')\n",
    "    fh.write(f'--lr: {lr}\\n')\n",
    "    fh.write(f'--csv_log: {path}/{csv_fname}.csv\\n')\n",
    "    fh.write(f'--best model: {path}/models/run_{i}.pth\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def multi_train(get_learn, epoch_len, epochs, opts, lrs, checkpoints, tb_log_root,autoSave=True, worseN_th = 5):\n",
    "    '''\n",
    "    可以从checkpoint继续训练，为了保证训练连续性，需要手动设置lr与checkpoint保存时一致。\n",
    "    '''\n",
    "    # 清理tensorboard log dir\n",
    "    if os.path.exists(tb_log_root): shutil.rmtree(tb_log_root)\n",
    "    os.mkdir(tb_log_root)\n",
    "    \n",
    "    if not os.path.exists('./run_log/'): os.mkdir('./run_log/')\n",
    "    txtlog = open('./run_log/log.txt',mode='w')\n",
    "    for i,(opt,lr,checkpoint) in enumerate(zip(opts,lrs,checkpoints)):\n",
    "        # create a learner\n",
    "        learn = get_learn()\n",
    "        \n",
    "        # set optimizer\n",
    "        learn.opt_func = opt\n",
    "        \n",
    "        # load checkpoint\n",
    "        if checkpoint is not None:\n",
    "            with open(checkpoint,'rb') as f:\n",
    "                learn.load(f)\n",
    "        \n",
    "        # 在txt log中记录\n",
    "        csv_log_dir = f'csv_log/'\n",
    "        if not os.path.exists(learn.path/csv_log_dir): os.mkdir(learn.path/csv_log_dir)\n",
    "        csv_fname = csv_log_dir+f'run_{i}'\n",
    "        txt_write(txtlog,i,opt,lr,learn.path,csv_fname)\n",
    "        \n",
    "        callbacks = []\n",
    "        # get csvlogger callback\n",
    "        csvLog = CSVLogger(learn,filename=csv_fname)\n",
    "        callbacks += [csvLog]\n",
    "        \n",
    "        if autoSave:\n",
    "            # savemodel callback\n",
    "            autoSave = SaveModelCallback(learn,monitor='valid_loss',mode='min',every='improvement',name=f'run_{i}')\n",
    "            callbacks += [autoSave]\n",
    "        \n",
    "        # get tensorboard callback\n",
    "        tbCb = get_tbCb(learn,tb_log_root+f'run_{i}')\n",
    "        callbacks += [tbCb]\n",
    "        \n",
    "        # train\n",
    "        fit(learn=learn, epoch_len=epoch_len, epochs=epochs, lr=lr, callbacks=callbacks, worseN_th = worseN_th)\n",
    "        \n",
    "    txtlog.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def get_tbCb(learn,log_dir):\n",
    "    tbCb = tensorboard_callback.TensorBoardCallback(\n",
    "                                   learn=learn,\n",
    "                                   log_dir=log_dir,\n",
    "                                   plot_net=False,\n",
    "                                   plot_loss=True,\n",
    "                                   metric_plots=['mask_iou'],\n",
    "                                   hyper_plots=['lr'],\n",
    "                                   hist_plots=['down_blocks.2.0.conv1.weight',\n",
    "                                               'up_blocks.2.conv1.conv.weight'],\n",
    "                                   hist_iters=50)\n",
    "    return tbCb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def fit(learn,epoch_len,epochs,lr,callbacks, worseN_th = 5):\n",
    "    scheduling_train.fit_with_warmup_multiAnnealPlat(learn,\n",
    "                                    epoch_len=epoch_len,\n",
    "                                    num_epoch=epochs,\n",
    "\n",
    "                                    lr_start=lr/10,\n",
    "                                    lr_constant=lr,\n",
    "                                    warmup_iter=10,\n",
    "\n",
    "                                    monitor='train_smooth',\n",
    "                                    worseN_thres=worseN_th,\n",
    "                                    annealRate=10,\n",
    "                                    duration_thres=30,\n",
    "                                    annealIte=10,\n",
    "                                    phaseMaxN=3,\n",
    "                                    finetune_stop=1,\n",
    "                                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "# 设置device\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "ds = './data/dataset_20200715'\n",
    "data = databunch.get_databunch(ds, bs=16, device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "opts = [partial(optimizer.Adam, betas=(0.9,0.99))]\n",
    "\n",
    "lrs = [1e-3]\n",
    "\n",
    "checkpoints = [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='9' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      90.00% [9/10 04:20<00:28]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice_loss</th>\n",
       "      <th>balance_bce</th>\n",
       "      <th>mask_iou</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.824198</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.810985</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.787584</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.741016</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.693493</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.646794</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.622510</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.598025</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.591812</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='9' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      90.00% [9/10 00:25<00:02 1.2695]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = get_learn(data)\n",
    "learn.opt_func = partial(optimizer.Adam, betas=(0.9,0.99))\n",
    "\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALLERT: You are using CumtomEpochLength, please make sure that your training dataloader is using random sampler, or this may cause problem.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='34' class='' max='500', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      6.80% [34/500 17:36<4:01:16]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice_loss</th>\n",
       "      <th>balance_bce</th>\n",
       "      <th>mask_iou</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.637225</td>\n",
       "      <td>0.686979</td>\n",
       "      <td>0.733969</td>\n",
       "      <td>0.686979</td>\n",
       "      <td>0.295283</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.584005</td>\n",
       "      <td>0.658344</td>\n",
       "      <td>0.724731</td>\n",
       "      <td>0.658344</td>\n",
       "      <td>0.292910</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.558554</td>\n",
       "      <td>0.593374</td>\n",
       "      <td>0.683038</td>\n",
       "      <td>0.593374</td>\n",
       "      <td>0.367078</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.541633</td>\n",
       "      <td>0.528907</td>\n",
       "      <td>0.624395</td>\n",
       "      <td>0.528907</td>\n",
       "      <td>0.360305</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.524296</td>\n",
       "      <td>0.487569</td>\n",
       "      <td>0.598474</td>\n",
       "      <td>0.487569</td>\n",
       "      <td>0.397460</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.507095</td>\n",
       "      <td>0.458037</td>\n",
       "      <td>0.553677</td>\n",
       "      <td>0.458037</td>\n",
       "      <td>0.426135</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.478728</td>\n",
       "      <td>0.414223</td>\n",
       "      <td>0.529840</td>\n",
       "      <td>0.414223</td>\n",
       "      <td>0.543120</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.444471</td>\n",
       "      <td>0.770592</td>\n",
       "      <td>0.682607</td>\n",
       "      <td>0.770592</td>\n",
       "      <td>0.174923</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.415729</td>\n",
       "      <td>0.358769</td>\n",
       "      <td>0.462537</td>\n",
       "      <td>0.358769</td>\n",
       "      <td>0.541597</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.386293</td>\n",
       "      <td>0.954995</td>\n",
       "      <td>0.593670</td>\n",
       "      <td>0.954995</td>\n",
       "      <td>0.251700</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.359401</td>\n",
       "      <td>0.416330</td>\n",
       "      <td>0.450419</td>\n",
       "      <td>0.416330</td>\n",
       "      <td>0.476352</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.339679</td>\n",
       "      <td>0.559469</td>\n",
       "      <td>0.403234</td>\n",
       "      <td>0.559469</td>\n",
       "      <td>0.505851</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.321699</td>\n",
       "      <td>0.341620</td>\n",
       "      <td>0.343187</td>\n",
       "      <td>0.341620</td>\n",
       "      <td>0.548216</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.300600</td>\n",
       "      <td>0.238867</td>\n",
       "      <td>0.295832</td>\n",
       "      <td>0.238867</td>\n",
       "      <td>0.622776</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.279727</td>\n",
       "      <td>0.345618</td>\n",
       "      <td>0.254018</td>\n",
       "      <td>0.345618</td>\n",
       "      <td>0.676386</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.264219</td>\n",
       "      <td>0.213251</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>0.213251</td>\n",
       "      <td>0.631880</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.247074</td>\n",
       "      <td>0.231501</td>\n",
       "      <td>0.313343</td>\n",
       "      <td>0.231501</td>\n",
       "      <td>0.648386</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.211019</td>\n",
       "      <td>0.295739</td>\n",
       "      <td>0.211019</td>\n",
       "      <td>0.635286</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.220193</td>\n",
       "      <td>0.213201</td>\n",
       "      <td>0.226232</td>\n",
       "      <td>0.213201</td>\n",
       "      <td>0.714630</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.208971</td>\n",
       "      <td>0.191117</td>\n",
       "      <td>0.230232</td>\n",
       "      <td>0.191117</td>\n",
       "      <td>0.691797</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.201248</td>\n",
       "      <td>0.162640</td>\n",
       "      <td>0.212242</td>\n",
       "      <td>0.162640</td>\n",
       "      <td>0.751598</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.194146</td>\n",
       "      <td>0.297543</td>\n",
       "      <td>0.241618</td>\n",
       "      <td>0.297543</td>\n",
       "      <td>0.730001</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.188915</td>\n",
       "      <td>0.343761</td>\n",
       "      <td>0.377706</td>\n",
       "      <td>0.343761</td>\n",
       "      <td>0.474320</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.180274</td>\n",
       "      <td>0.159498</td>\n",
       "      <td>0.222711</td>\n",
       "      <td>0.159498</td>\n",
       "      <td>0.743722</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.176677</td>\n",
       "      <td>0.301703</td>\n",
       "      <td>0.224717</td>\n",
       "      <td>0.301703</td>\n",
       "      <td>0.724950</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.170082</td>\n",
       "      <td>0.402320</td>\n",
       "      <td>0.248305</td>\n",
       "      <td>0.402320</td>\n",
       "      <td>0.681468</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.168645</td>\n",
       "      <td>0.185809</td>\n",
       "      <td>0.194620</td>\n",
       "      <td>0.185809</td>\n",
       "      <td>0.732839</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.164293</td>\n",
       "      <td>0.197328</td>\n",
       "      <td>0.207935</td>\n",
       "      <td>0.197328</td>\n",
       "      <td>0.792077</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.157258</td>\n",
       "      <td>0.234070</td>\n",
       "      <td>0.193899</td>\n",
       "      <td>0.234070</td>\n",
       "      <td>0.737575</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.157193</td>\n",
       "      <td>0.183978</td>\n",
       "      <td>0.187644</td>\n",
       "      <td>0.183978</td>\n",
       "      <td>0.744727</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.156975</td>\n",
       "      <td>0.597949</td>\n",
       "      <td>0.453081</td>\n",
       "      <td>0.597949</td>\n",
       "      <td>0.419353</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.153414</td>\n",
       "      <td>0.145166</td>\n",
       "      <td>0.172663</td>\n",
       "      <td>0.145166</td>\n",
       "      <td>0.778849</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.147448</td>\n",
       "      <td>0.132256</td>\n",
       "      <td>0.174366</td>\n",
       "      <td>0.132256</td>\n",
       "      <td>0.773687</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.141147</td>\n",
       "      <td>0.157870</td>\n",
       "      <td>0.146333</td>\n",
       "      <td>0.157870</td>\n",
       "      <td>0.819111</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='7' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      70.00% [7/10 00:19<00:08 0.1378]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.6869791746139526.\n",
      "Better model found at epoch 1 with valid_loss value: 0.6583436131477356.\n",
      "Better model found at epoch 2 with valid_loss value: 0.5933743715286255.\n",
      "Better model found at epoch 3 with valid_loss value: 0.5289066433906555.\n",
      "Better model found at epoch 4 with valid_loss value: 0.48756909370422363.\n",
      "Better model found at epoch 5 with valid_loss value: 0.45803719758987427.\n",
      "Better model found at epoch 6 with valid_loss value: 0.4142228662967682.\n",
      "Better model found at epoch 8 with valid_loss value: 0.35876917839050293.\n",
      "Better model found at epoch 12 with valid_loss value: 0.34162041544914246.\n",
      "Better model found at epoch 13 with valid_loss value: 0.23886704444885254.\n",
      "Better model found at epoch 15 with valid_loss value: 0.21325120329856873.\n",
      "Better model found at epoch 17 with valid_loss value: 0.21101875603199005.\n",
      "Better model found at epoch 19 with valid_loss value: 0.19111721217632294.\n",
      "Better model found at epoch 20 with valid_loss value: 0.16264010965824127.\n",
      "Better model found at epoch 23 with valid_loss value: 0.15949757397174835.\n",
      "Better model found at epoch 31 with valid_loss value: 0.14516615867614746.\n",
      "Better model found at epoch 32 with valid_loss value: 0.13225629925727844.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-254accc7d7f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mopts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mtb_log_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./tb_log/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             autoSave=True)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-fb7de2ecc1e0>\u001b[0m in \u001b[0;36mmulti_train\u001b[0;34m(get_learn, epoch_len, epochs, opts, lrs, checkpoints, tb_log_root, autoSave)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mtxtlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-930251caec4d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(learn, epoch_len, epochs, lr, callbacks)\u001b[0m\n\u001b[1;32m     16\u001b[0m                                     \u001b[0mphaseMaxN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                     \u001b[0mfinetune_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                     callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/home/dev/jupyter/unet/exp/nb_scheduling_train.py\u001b[0m in \u001b[0;36mfit_with_warmup_multiAnnealPlat\u001b[0;34m(learn, epoch_len, num_epoch, lr_start, lr_constant, warmup_iter, monitor, worseN_thres, annealRate, duration_thres, annealIte, phaseMaxN, finetune_stop, callbacks)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_epochLen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpg2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_no_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/jupyter/unet/exp/nb_optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;31m# debias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mm_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0mv_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;31m# update value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "multi_train(get_learn=partial(resnet_unet.get_learn,data=data), \n",
    "            epoch_len=1e9, epochs=500,\n",
    "            opts=opts, lrs=lrs, checkpoints=checkpoints,\n",
    "            tb_log_root='./tb_log/',\n",
    "            autoSave=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALLERT: You are using CumtomEpochLength, please make sure that your training dataloader is using random sampler, or this may cause problem.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='173' class='' max='500', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      34.60% [173/500 1:29:58<2:50:04]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice_loss</th>\n",
       "      <th>balance_bce</th>\n",
       "      <th>mask_iou</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.559014</td>\n",
       "      <td>0.696392</td>\n",
       "      <td>0.716869</td>\n",
       "      <td>0.696392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.506591</td>\n",
       "      <td>0.663716</td>\n",
       "      <td>0.696999</td>\n",
       "      <td>0.663716</td>\n",
       "      <td>0.326093</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.484401</td>\n",
       "      <td>0.613259</td>\n",
       "      <td>0.664939</td>\n",
       "      <td>0.613259</td>\n",
       "      <td>0.385476</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.463973</td>\n",
       "      <td>0.537986</td>\n",
       "      <td>0.605159</td>\n",
       "      <td>0.537986</td>\n",
       "      <td>0.399828</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.439107</td>\n",
       "      <td>0.459481</td>\n",
       "      <td>0.538257</td>\n",
       "      <td>0.459481</td>\n",
       "      <td>0.469730</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.412740</td>\n",
       "      <td>0.410764</td>\n",
       "      <td>0.482823</td>\n",
       "      <td>0.410764</td>\n",
       "      <td>0.442997</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.376710</td>\n",
       "      <td>0.264881</td>\n",
       "      <td>0.315373</td>\n",
       "      <td>0.264881</td>\n",
       "      <td>0.708487</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.346964</td>\n",
       "      <td>0.288355</td>\n",
       "      <td>0.329674</td>\n",
       "      <td>0.288355</td>\n",
       "      <td>0.593468</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.317036</td>\n",
       "      <td>0.269857</td>\n",
       "      <td>0.285794</td>\n",
       "      <td>0.269857</td>\n",
       "      <td>0.684629</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.287659</td>\n",
       "      <td>0.190840</td>\n",
       "      <td>0.189843</td>\n",
       "      <td>0.190840</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.263015</td>\n",
       "      <td>0.249935</td>\n",
       "      <td>0.197902</td>\n",
       "      <td>0.249935</td>\n",
       "      <td>0.750524</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.243351</td>\n",
       "      <td>0.287790</td>\n",
       "      <td>0.357484</td>\n",
       "      <td>0.287790</td>\n",
       "      <td>0.529102</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.232229</td>\n",
       "      <td>0.565444</td>\n",
       "      <td>0.465712</td>\n",
       "      <td>0.565444</td>\n",
       "      <td>0.390122</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.218369</td>\n",
       "      <td>0.169630</td>\n",
       "      <td>0.232036</td>\n",
       "      <td>0.169630</td>\n",
       "      <td>0.751778</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.203087</td>\n",
       "      <td>0.166380</td>\n",
       "      <td>0.142501</td>\n",
       "      <td>0.166380</td>\n",
       "      <td>0.814977</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.189567</td>\n",
       "      <td>0.156561</td>\n",
       "      <td>0.203870</td>\n",
       "      <td>0.156561</td>\n",
       "      <td>0.712159</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.177789</td>\n",
       "      <td>0.117234</td>\n",
       "      <td>0.120872</td>\n",
       "      <td>0.117234</td>\n",
       "      <td>0.839052</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.164954</td>\n",
       "      <td>0.118035</td>\n",
       "      <td>0.166879</td>\n",
       "      <td>0.118035</td>\n",
       "      <td>0.790830</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.162908</td>\n",
       "      <td>0.281168</td>\n",
       "      <td>0.172138</td>\n",
       "      <td>0.281168</td>\n",
       "      <td>0.734565</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.167292</td>\n",
       "      <td>0.202766</td>\n",
       "      <td>0.243577</td>\n",
       "      <td>0.202766</td>\n",
       "      <td>0.677487</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.163888</td>\n",
       "      <td>0.405340</td>\n",
       "      <td>0.310421</td>\n",
       "      <td>0.405340</td>\n",
       "      <td>0.574118</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.158969</td>\n",
       "      <td>0.194708</td>\n",
       "      <td>0.187648</td>\n",
       "      <td>0.194708</td>\n",
       "      <td>0.798284</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.153193</td>\n",
       "      <td>0.128068</td>\n",
       "      <td>0.122898</td>\n",
       "      <td>0.128068</td>\n",
       "      <td>0.837271</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.148092</td>\n",
       "      <td>0.186166</td>\n",
       "      <td>0.161526</td>\n",
       "      <td>0.186166</td>\n",
       "      <td>0.797554</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.141793</td>\n",
       "      <td>0.139050</td>\n",
       "      <td>0.136910</td>\n",
       "      <td>0.139050</td>\n",
       "      <td>0.816771</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.135451</td>\n",
       "      <td>0.105633</td>\n",
       "      <td>0.120344</td>\n",
       "      <td>0.105633</td>\n",
       "      <td>0.860003</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.132305</td>\n",
       "      <td>0.237914</td>\n",
       "      <td>0.285510</td>\n",
       "      <td>0.237914</td>\n",
       "      <td>0.582573</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.129184</td>\n",
       "      <td>0.133243</td>\n",
       "      <td>0.140755</td>\n",
       "      <td>0.133243</td>\n",
       "      <td>0.827354</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.126555</td>\n",
       "      <td>0.216736</td>\n",
       "      <td>0.149911</td>\n",
       "      <td>0.216736</td>\n",
       "      <td>0.819171</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.112849</td>\n",
       "      <td>0.168644</td>\n",
       "      <td>0.112849</td>\n",
       "      <td>0.781695</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.117254</td>\n",
       "      <td>0.092834</td>\n",
       "      <td>0.112130</td>\n",
       "      <td>0.092834</td>\n",
       "      <td>0.853105</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.112205</td>\n",
       "      <td>0.120023</td>\n",
       "      <td>0.137842</td>\n",
       "      <td>0.120023</td>\n",
       "      <td>0.843345</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.107279</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.107436</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.851957</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.102909</td>\n",
       "      <td>0.088607</td>\n",
       "      <td>0.110783</td>\n",
       "      <td>0.088607</td>\n",
       "      <td>0.843139</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.098485</td>\n",
       "      <td>0.090045</td>\n",
       "      <td>0.108066</td>\n",
       "      <td>0.090045</td>\n",
       "      <td>0.840553</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.094077</td>\n",
       "      <td>0.085342</td>\n",
       "      <td>0.120448</td>\n",
       "      <td>0.085342</td>\n",
       "      <td>0.828971</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.090449</td>\n",
       "      <td>0.101651</td>\n",
       "      <td>0.138456</td>\n",
       "      <td>0.101651</td>\n",
       "      <td>0.792930</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.087350</td>\n",
       "      <td>0.135467</td>\n",
       "      <td>0.130317</td>\n",
       "      <td>0.135467</td>\n",
       "      <td>0.857742</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.084621</td>\n",
       "      <td>0.097371</td>\n",
       "      <td>0.135395</td>\n",
       "      <td>0.097371</td>\n",
       "      <td>0.793307</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.082837</td>\n",
       "      <td>0.110151</td>\n",
       "      <td>0.151449</td>\n",
       "      <td>0.110151</td>\n",
       "      <td>0.756557</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.081815</td>\n",
       "      <td>0.081356</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>0.081356</td>\n",
       "      <td>0.826301</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.081574</td>\n",
       "      <td>0.185941</td>\n",
       "      <td>0.113444</td>\n",
       "      <td>0.185941</td>\n",
       "      <td>0.830277</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.091576</td>\n",
       "      <td>0.159543</td>\n",
       "      <td>0.142813</td>\n",
       "      <td>0.159543</td>\n",
       "      <td>0.773539</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.094571</td>\n",
       "      <td>0.220541</td>\n",
       "      <td>0.273461</td>\n",
       "      <td>0.220541</td>\n",
       "      <td>0.610095</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.093975</td>\n",
       "      <td>0.099588</td>\n",
       "      <td>0.105950</td>\n",
       "      <td>0.099588</td>\n",
       "      <td>0.863926</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.091167</td>\n",
       "      <td>0.108885</td>\n",
       "      <td>0.138803</td>\n",
       "      <td>0.108885</td>\n",
       "      <td>0.781460</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.087697</td>\n",
       "      <td>0.078422</td>\n",
       "      <td>0.097310</td>\n",
       "      <td>0.078422</td>\n",
       "      <td>0.869534</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.083778</td>\n",
       "      <td>0.075210</td>\n",
       "      <td>0.102663</td>\n",
       "      <td>0.075210</td>\n",
       "      <td>0.849463</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.080050</td>\n",
       "      <td>0.070299</td>\n",
       "      <td>0.093157</td>\n",
       "      <td>0.070299</td>\n",
       "      <td>0.864891</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.076180</td>\n",
       "      <td>0.068434</td>\n",
       "      <td>0.090173</td>\n",
       "      <td>0.068434</td>\n",
       "      <td>0.872737</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.073294</td>\n",
       "      <td>0.070703</td>\n",
       "      <td>0.097369</td>\n",
       "      <td>0.070703</td>\n",
       "      <td>0.861035</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.071051</td>\n",
       "      <td>0.067978</td>\n",
       "      <td>0.088838</td>\n",
       "      <td>0.067978</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.069010</td>\n",
       "      <td>0.068113</td>\n",
       "      <td>0.089758</td>\n",
       "      <td>0.068113</td>\n",
       "      <td>0.871241</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.066341</td>\n",
       "      <td>0.068058</td>\n",
       "      <td>0.089407</td>\n",
       "      <td>0.068058</td>\n",
       "      <td>0.866972</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.064599</td>\n",
       "      <td>0.068833</td>\n",
       "      <td>0.084573</td>\n",
       "      <td>0.068833</td>\n",
       "      <td>0.876997</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.063398</td>\n",
       "      <td>0.067155</td>\n",
       "      <td>0.086025</td>\n",
       "      <td>0.067155</td>\n",
       "      <td>0.873497</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.061991</td>\n",
       "      <td>0.067048</td>\n",
       "      <td>0.083994</td>\n",
       "      <td>0.067048</td>\n",
       "      <td>0.878229</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.060882</td>\n",
       "      <td>0.067840</td>\n",
       "      <td>0.080354</td>\n",
       "      <td>0.067840</td>\n",
       "      <td>0.885895</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.059905</td>\n",
       "      <td>0.067125</td>\n",
       "      <td>0.079727</td>\n",
       "      <td>0.067125</td>\n",
       "      <td>0.884972</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.059197</td>\n",
       "      <td>0.067207</td>\n",
       "      <td>0.081813</td>\n",
       "      <td>0.067207</td>\n",
       "      <td>0.881173</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.058559</td>\n",
       "      <td>0.068589</td>\n",
       "      <td>0.090519</td>\n",
       "      <td>0.068589</td>\n",
       "      <td>0.868289</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.057395</td>\n",
       "      <td>0.066766</td>\n",
       "      <td>0.084877</td>\n",
       "      <td>0.066766</td>\n",
       "      <td>0.879058</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.056738</td>\n",
       "      <td>0.067085</td>\n",
       "      <td>0.079665</td>\n",
       "      <td>0.067085</td>\n",
       "      <td>0.886080</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.055774</td>\n",
       "      <td>0.064919</td>\n",
       "      <td>0.080126</td>\n",
       "      <td>0.064919</td>\n",
       "      <td>0.882813</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.055609</td>\n",
       "      <td>0.064994</td>\n",
       "      <td>0.078638</td>\n",
       "      <td>0.064994</td>\n",
       "      <td>0.882825</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.055830</td>\n",
       "      <td>0.067074</td>\n",
       "      <td>0.079354</td>\n",
       "      <td>0.067074</td>\n",
       "      <td>0.885238</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.055214</td>\n",
       "      <td>0.069702</td>\n",
       "      <td>0.091304</td>\n",
       "      <td>0.069702</td>\n",
       "      <td>0.864885</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.054550</td>\n",
       "      <td>0.067715</td>\n",
       "      <td>0.084325</td>\n",
       "      <td>0.067715</td>\n",
       "      <td>0.878065</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.054480</td>\n",
       "      <td>0.068042</td>\n",
       "      <td>0.079825</td>\n",
       "      <td>0.068042</td>\n",
       "      <td>0.887856</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.054192</td>\n",
       "      <td>0.066410</td>\n",
       "      <td>0.079902</td>\n",
       "      <td>0.066410</td>\n",
       "      <td>0.883735</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.054745</td>\n",
       "      <td>0.067746</td>\n",
       "      <td>0.085547</td>\n",
       "      <td>0.067746</td>\n",
       "      <td>0.867446</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.054038</td>\n",
       "      <td>0.065718</td>\n",
       "      <td>0.080084</td>\n",
       "      <td>0.065718</td>\n",
       "      <td>0.883315</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.053241</td>\n",
       "      <td>0.064904</td>\n",
       "      <td>0.081386</td>\n",
       "      <td>0.064904</td>\n",
       "      <td>0.877869</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.053029</td>\n",
       "      <td>0.068406</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>0.068406</td>\n",
       "      <td>0.885428</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.052640</td>\n",
       "      <td>0.065809</td>\n",
       "      <td>0.074045</td>\n",
       "      <td>0.065809</td>\n",
       "      <td>0.891263</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.051942</td>\n",
       "      <td>0.063741</td>\n",
       "      <td>0.076570</td>\n",
       "      <td>0.063741</td>\n",
       "      <td>0.887923</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.051060</td>\n",
       "      <td>0.064654</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.064654</td>\n",
       "      <td>0.885377</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.050837</td>\n",
       "      <td>0.066329</td>\n",
       "      <td>0.079166</td>\n",
       "      <td>0.066329</td>\n",
       "      <td>0.879893</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.050521</td>\n",
       "      <td>0.065415</td>\n",
       "      <td>0.077317</td>\n",
       "      <td>0.065415</td>\n",
       "      <td>0.882915</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.050056</td>\n",
       "      <td>0.069696</td>\n",
       "      <td>0.082880</td>\n",
       "      <td>0.069696</td>\n",
       "      <td>0.878397</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.050022</td>\n",
       "      <td>0.063501</td>\n",
       "      <td>0.075160</td>\n",
       "      <td>0.063501</td>\n",
       "      <td>0.891037</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.049947</td>\n",
       "      <td>0.063819</td>\n",
       "      <td>0.078479</td>\n",
       "      <td>0.063819</td>\n",
       "      <td>0.881421</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.049620</td>\n",
       "      <td>0.064379</td>\n",
       "      <td>0.077320</td>\n",
       "      <td>0.064379</td>\n",
       "      <td>0.887519</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.049760</td>\n",
       "      <td>0.065221</td>\n",
       "      <td>0.082920</td>\n",
       "      <td>0.065221</td>\n",
       "      <td>0.871184</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.049365</td>\n",
       "      <td>0.066136</td>\n",
       "      <td>0.073503</td>\n",
       "      <td>0.066136</td>\n",
       "      <td>0.891571</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.049093</td>\n",
       "      <td>0.066078</td>\n",
       "      <td>0.074656</td>\n",
       "      <td>0.066078</td>\n",
       "      <td>0.888354</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.048841</td>\n",
       "      <td>0.063202</td>\n",
       "      <td>0.072196</td>\n",
       "      <td>0.063202</td>\n",
       "      <td>0.890683</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.048134</td>\n",
       "      <td>0.065445</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>0.065445</td>\n",
       "      <td>0.890852</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.048166</td>\n",
       "      <td>0.063959</td>\n",
       "      <td>0.077137</td>\n",
       "      <td>0.063959</td>\n",
       "      <td>0.880955</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.047696</td>\n",
       "      <td>0.065941</td>\n",
       "      <td>0.080627</td>\n",
       "      <td>0.065941</td>\n",
       "      <td>0.883350</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.047778</td>\n",
       "      <td>0.064939</td>\n",
       "      <td>0.073513</td>\n",
       "      <td>0.064939</td>\n",
       "      <td>0.887050</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.047763</td>\n",
       "      <td>0.062977</td>\n",
       "      <td>0.074997</td>\n",
       "      <td>0.062977</td>\n",
       "      <td>0.885638</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.047537</td>\n",
       "      <td>0.064024</td>\n",
       "      <td>0.079590</td>\n",
       "      <td>0.064024</td>\n",
       "      <td>0.881424</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.047337</td>\n",
       "      <td>0.062495</td>\n",
       "      <td>0.074064</td>\n",
       "      <td>0.062495</td>\n",
       "      <td>0.887317</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.047099</td>\n",
       "      <td>0.064964</td>\n",
       "      <td>0.077979</td>\n",
       "      <td>0.064964</td>\n",
       "      <td>0.887328</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.046828</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.072991</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.890561</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.046837</td>\n",
       "      <td>0.064590</td>\n",
       "      <td>0.078167</td>\n",
       "      <td>0.064590</td>\n",
       "      <td>0.879970</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.047144</td>\n",
       "      <td>0.064614</td>\n",
       "      <td>0.080252</td>\n",
       "      <td>0.064614</td>\n",
       "      <td>0.878385</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.046744</td>\n",
       "      <td>0.062091</td>\n",
       "      <td>0.077525</td>\n",
       "      <td>0.062091</td>\n",
       "      <td>0.882570</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.046530</td>\n",
       "      <td>0.063794</td>\n",
       "      <td>0.069910</td>\n",
       "      <td>0.063794</td>\n",
       "      <td>0.897482</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.046198</td>\n",
       "      <td>0.064818</td>\n",
       "      <td>0.069208</td>\n",
       "      <td>0.064818</td>\n",
       "      <td>0.901366</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.045558</td>\n",
       "      <td>0.062655</td>\n",
       "      <td>0.073944</td>\n",
       "      <td>0.062655</td>\n",
       "      <td>0.887860</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.045471</td>\n",
       "      <td>0.061114</td>\n",
       "      <td>0.070281</td>\n",
       "      <td>0.061114</td>\n",
       "      <td>0.891729</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.045221</td>\n",
       "      <td>0.063189</td>\n",
       "      <td>0.070472</td>\n",
       "      <td>0.063189</td>\n",
       "      <td>0.892062</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.044952</td>\n",
       "      <td>0.062442</td>\n",
       "      <td>0.071425</td>\n",
       "      <td>0.062442</td>\n",
       "      <td>0.891660</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.044730</td>\n",
       "      <td>0.063621</td>\n",
       "      <td>0.070310</td>\n",
       "      <td>0.063621</td>\n",
       "      <td>0.893656</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.044695</td>\n",
       "      <td>0.062174</td>\n",
       "      <td>0.075833</td>\n",
       "      <td>0.062174</td>\n",
       "      <td>0.880710</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.044317</td>\n",
       "      <td>0.061954</td>\n",
       "      <td>0.071479</td>\n",
       "      <td>0.061954</td>\n",
       "      <td>0.888960</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.043897</td>\n",
       "      <td>0.062717</td>\n",
       "      <td>0.073220</td>\n",
       "      <td>0.062717</td>\n",
       "      <td>0.889965</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.043947</td>\n",
       "      <td>0.063735</td>\n",
       "      <td>0.073846</td>\n",
       "      <td>0.063735</td>\n",
       "      <td>0.887437</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.043699</td>\n",
       "      <td>0.063001</td>\n",
       "      <td>0.073348</td>\n",
       "      <td>0.063001</td>\n",
       "      <td>0.885802</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.043353</td>\n",
       "      <td>0.066096</td>\n",
       "      <td>0.067663</td>\n",
       "      <td>0.066096</td>\n",
       "      <td>0.899400</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.043330</td>\n",
       "      <td>0.062725</td>\n",
       "      <td>0.067234</td>\n",
       "      <td>0.062725</td>\n",
       "      <td>0.896988</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.043522</td>\n",
       "      <td>0.063467</td>\n",
       "      <td>0.079257</td>\n",
       "      <td>0.063467</td>\n",
       "      <td>0.878002</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.043098</td>\n",
       "      <td>0.062758</td>\n",
       "      <td>0.070583</td>\n",
       "      <td>0.062758</td>\n",
       "      <td>0.895681</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.042769</td>\n",
       "      <td>0.062117</td>\n",
       "      <td>0.067238</td>\n",
       "      <td>0.062117</td>\n",
       "      <td>0.896119</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.042370</td>\n",
       "      <td>0.062657</td>\n",
       "      <td>0.070132</td>\n",
       "      <td>0.062657</td>\n",
       "      <td>0.891137</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.042082</td>\n",
       "      <td>0.062087</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.062087</td>\n",
       "      <td>0.896707</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.042131</td>\n",
       "      <td>0.061658</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.061658</td>\n",
       "      <td>0.894207</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.042006</td>\n",
       "      <td>0.062759</td>\n",
       "      <td>0.068916</td>\n",
       "      <td>0.062759</td>\n",
       "      <td>0.894482</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.042062</td>\n",
       "      <td>0.061726</td>\n",
       "      <td>0.071384</td>\n",
       "      <td>0.061726</td>\n",
       "      <td>0.891744</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.041663</td>\n",
       "      <td>0.062726</td>\n",
       "      <td>0.068463</td>\n",
       "      <td>0.062726</td>\n",
       "      <td>0.895906</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.041999</td>\n",
       "      <td>0.061909</td>\n",
       "      <td>0.068777</td>\n",
       "      <td>0.061909</td>\n",
       "      <td>0.895336</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.042226</td>\n",
       "      <td>0.062093</td>\n",
       "      <td>0.071280</td>\n",
       "      <td>0.062093</td>\n",
       "      <td>0.890319</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.042325</td>\n",
       "      <td>0.062147</td>\n",
       "      <td>0.069541</td>\n",
       "      <td>0.062147</td>\n",
       "      <td>0.892749</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.042029</td>\n",
       "      <td>0.062183</td>\n",
       "      <td>0.069281</td>\n",
       "      <td>0.062183</td>\n",
       "      <td>0.893810</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.042147</td>\n",
       "      <td>0.061395</td>\n",
       "      <td>0.067852</td>\n",
       "      <td>0.061395</td>\n",
       "      <td>0.895998</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.041979</td>\n",
       "      <td>0.062030</td>\n",
       "      <td>0.067657</td>\n",
       "      <td>0.062030</td>\n",
       "      <td>0.894983</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.041423</td>\n",
       "      <td>0.061091</td>\n",
       "      <td>0.067176</td>\n",
       "      <td>0.061091</td>\n",
       "      <td>0.895702</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.041114</td>\n",
       "      <td>0.060845</td>\n",
       "      <td>0.068636</td>\n",
       "      <td>0.060845</td>\n",
       "      <td>0.893574</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.040840</td>\n",
       "      <td>0.061096</td>\n",
       "      <td>0.068327</td>\n",
       "      <td>0.061096</td>\n",
       "      <td>0.895212</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.040721</td>\n",
       "      <td>0.061267</td>\n",
       "      <td>0.068213</td>\n",
       "      <td>0.061267</td>\n",
       "      <td>0.895435</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.040575</td>\n",
       "      <td>0.060795</td>\n",
       "      <td>0.068561</td>\n",
       "      <td>0.060795</td>\n",
       "      <td>0.893507</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.040460</td>\n",
       "      <td>0.061471</td>\n",
       "      <td>0.066365</td>\n",
       "      <td>0.061471</td>\n",
       "      <td>0.898558</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.040241</td>\n",
       "      <td>0.060727</td>\n",
       "      <td>0.067006</td>\n",
       "      <td>0.060727</td>\n",
       "      <td>0.897487</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.040026</td>\n",
       "      <td>0.060934</td>\n",
       "      <td>0.067315</td>\n",
       "      <td>0.060934</td>\n",
       "      <td>0.897050</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.040168</td>\n",
       "      <td>0.061431</td>\n",
       "      <td>0.067203</td>\n",
       "      <td>0.061431</td>\n",
       "      <td>0.896529</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.040248</td>\n",
       "      <td>0.061128</td>\n",
       "      <td>0.066847</td>\n",
       "      <td>0.061128</td>\n",
       "      <td>0.896776</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.061158</td>\n",
       "      <td>0.067710</td>\n",
       "      <td>0.061158</td>\n",
       "      <td>0.894738</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.040486</td>\n",
       "      <td>0.060111</td>\n",
       "      <td>0.067869</td>\n",
       "      <td>0.060111</td>\n",
       "      <td>0.895700</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.040121</td>\n",
       "      <td>0.060666</td>\n",
       "      <td>0.067009</td>\n",
       "      <td>0.060666</td>\n",
       "      <td>0.897451</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.040087</td>\n",
       "      <td>0.061757</td>\n",
       "      <td>0.066356</td>\n",
       "      <td>0.061757</td>\n",
       "      <td>0.897492</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.039779</td>\n",
       "      <td>0.061351</td>\n",
       "      <td>0.066167</td>\n",
       "      <td>0.061351</td>\n",
       "      <td>0.898692</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.039592</td>\n",
       "      <td>0.061807</td>\n",
       "      <td>0.067782</td>\n",
       "      <td>0.061807</td>\n",
       "      <td>0.896277</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.039703</td>\n",
       "      <td>0.061669</td>\n",
       "      <td>0.068814</td>\n",
       "      <td>0.061669</td>\n",
       "      <td>0.892860</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.040084</td>\n",
       "      <td>0.060734</td>\n",
       "      <td>0.067718</td>\n",
       "      <td>0.060734</td>\n",
       "      <td>0.896011</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.039921</td>\n",
       "      <td>0.060898</td>\n",
       "      <td>0.068077</td>\n",
       "      <td>0.060898</td>\n",
       "      <td>0.895040</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.039985</td>\n",
       "      <td>0.060152</td>\n",
       "      <td>0.066968</td>\n",
       "      <td>0.060152</td>\n",
       "      <td>0.896336</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.039831</td>\n",
       "      <td>0.061085</td>\n",
       "      <td>0.067173</td>\n",
       "      <td>0.061085</td>\n",
       "      <td>0.896870</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.039607</td>\n",
       "      <td>0.061241</td>\n",
       "      <td>0.066778</td>\n",
       "      <td>0.061241</td>\n",
       "      <td>0.897323</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.039506</td>\n",
       "      <td>0.061275</td>\n",
       "      <td>0.066834</td>\n",
       "      <td>0.061275</td>\n",
       "      <td>0.896547</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.039408</td>\n",
       "      <td>0.061056</td>\n",
       "      <td>0.067709</td>\n",
       "      <td>0.061056</td>\n",
       "      <td>0.896202</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.039321</td>\n",
       "      <td>0.060919</td>\n",
       "      <td>0.065113</td>\n",
       "      <td>0.060919</td>\n",
       "      <td>0.900059</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.039531</td>\n",
       "      <td>0.059208</td>\n",
       "      <td>0.066422</td>\n",
       "      <td>0.059208</td>\n",
       "      <td>0.898342</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.039314</td>\n",
       "      <td>0.059190</td>\n",
       "      <td>0.067409</td>\n",
       "      <td>0.059190</td>\n",
       "      <td>0.896570</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.039128</td>\n",
       "      <td>0.060445</td>\n",
       "      <td>0.066595</td>\n",
       "      <td>0.060445</td>\n",
       "      <td>0.897539</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.039283</td>\n",
       "      <td>0.060287</td>\n",
       "      <td>0.066613</td>\n",
       "      <td>0.060287</td>\n",
       "      <td>0.896292</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.039167</td>\n",
       "      <td>0.060754</td>\n",
       "      <td>0.065481</td>\n",
       "      <td>0.060754</td>\n",
       "      <td>0.898930</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.039318</td>\n",
       "      <td>0.060307</td>\n",
       "      <td>0.066520</td>\n",
       "      <td>0.060307</td>\n",
       "      <td>0.896693</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.039252</td>\n",
       "      <td>0.060883</td>\n",
       "      <td>0.066785</td>\n",
       "      <td>0.060883</td>\n",
       "      <td>0.897028</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.038927</td>\n",
       "      <td>0.060472</td>\n",
       "      <td>0.065286</td>\n",
       "      <td>0.060472</td>\n",
       "      <td>0.900070</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.038915</td>\n",
       "      <td>0.060454</td>\n",
       "      <td>0.066644</td>\n",
       "      <td>0.060454</td>\n",
       "      <td>0.896727</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.039033</td>\n",
       "      <td>0.061220</td>\n",
       "      <td>0.066817</td>\n",
       "      <td>0.061220</td>\n",
       "      <td>0.898278</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.038782</td>\n",
       "      <td>0.060651</td>\n",
       "      <td>0.065554</td>\n",
       "      <td>0.060651</td>\n",
       "      <td>0.898026</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.038846</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.064591</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.899724</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.038627</td>\n",
       "      <td>0.060705</td>\n",
       "      <td>0.064997</td>\n",
       "      <td>0.060705</td>\n",
       "      <td>0.900807</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.038289</td>\n",
       "      <td>0.061079</td>\n",
       "      <td>0.065899</td>\n",
       "      <td>0.061079</td>\n",
       "      <td>0.898473</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.038529</td>\n",
       "      <td>0.060646</td>\n",
       "      <td>0.064277</td>\n",
       "      <td>0.060646</td>\n",
       "      <td>0.900151</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.038904</td>\n",
       "      <td>0.059438</td>\n",
       "      <td>0.064399</td>\n",
       "      <td>0.059438</td>\n",
       "      <td>0.901412</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.038607</td>\n",
       "      <td>0.058981</td>\n",
       "      <td>0.067435</td>\n",
       "      <td>0.058981</td>\n",
       "      <td>0.896197</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.038559</td>\n",
       "      <td>0.059379</td>\n",
       "      <td>0.066347</td>\n",
       "      <td>0.059379</td>\n",
       "      <td>0.897650</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.038431</td>\n",
       "      <td>0.060269</td>\n",
       "      <td>0.065915</td>\n",
       "      <td>0.060269</td>\n",
       "      <td>0.897450</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.038564</td>\n",
       "      <td>0.060691</td>\n",
       "      <td>0.066629</td>\n",
       "      <td>0.060691</td>\n",
       "      <td>0.896584</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3' class='' max='3', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:02<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.6963922381401062.\n",
      "Better model found at epoch 1 with valid_loss value: 0.663715660572052.\n",
      "Better model found at epoch 2 with valid_loss value: 0.613258957862854.\n",
      "Better model found at epoch 3 with valid_loss value: 0.5379860997200012.\n",
      "Better model found at epoch 4 with valid_loss value: 0.45948106050491333.\n",
      "Better model found at epoch 5 with valid_loss value: 0.4107644557952881.\n",
      "Better model found at epoch 6 with valid_loss value: 0.26488083600997925.\n",
      "Better model found at epoch 9 with valid_loss value: 0.1908400058746338.\n",
      "Better model found at epoch 13 with valid_loss value: 0.1696300208568573.\n",
      "Better model found at epoch 14 with valid_loss value: 0.16637985408306122.\n",
      "Better model found at epoch 15 with valid_loss value: 0.15656128525733948.\n",
      "Better model found at epoch 16 with valid_loss value: 0.11723385006189346.\n",
      "Better model found at epoch 25 with valid_loss value: 0.1056334599852562.\n",
      "Better model found at epoch 30 with valid_loss value: 0.0928344801068306.\n",
      "Better model found at epoch 32 with valid_loss value: 0.08849386870861053.\n",
      "Better model found at epoch 35 with valid_loss value: 0.08534186333417892.\n",
      "Better model found at epoch 40 with valid_loss value: 0.08135577291250229.\n",
      "Better model found at epoch 46 with valid_loss value: 0.07842232286930084.\n",
      "on end of epoch#46: start annealing from 0.001 to 0.0001\n",
      "Better model found at epoch 47 with valid_loss value: 0.07521016895771027.\n",
      "Better model found at epoch 48 with valid_loss value: 0.07029895484447479.\n",
      "Better model found at epoch 49 with valid_loss value: 0.06843428313732147.\n",
      "Better model found at epoch 51 with valid_loss value: 0.06797836720943451.\n",
      "Better model found at epoch 55 with valid_loss value: 0.06715518236160278.\n",
      "Better model found at epoch 56 with valid_loss value: 0.06704793870449066.\n",
      "Better model found at epoch 61 with valid_loss value: 0.06676562130451202.\n",
      "Better model found at epoch 63 with valid_loss value: 0.06491930782794952.\n",
      "Better model found at epoch 72 with valid_loss value: 0.06490395963191986.\n",
      "Better model found at epoch 75 with valid_loss value: 0.06374134123325348.\n",
      "Better model found at epoch 80 with valid_loss value: 0.06350065022706985.\n",
      "Better model found at epoch 86 with valid_loss value: 0.06320209801197052.\n",
      "Better model found at epoch 91 with valid_loss value: 0.06297697871923447.\n",
      "Better model found at epoch 93 with valid_loss value: 0.062494970858097076.\n",
      "Better model found at epoch 95 with valid_loss value: 0.06186680868268013.\n",
      "Better model found at epoch 102 with valid_loss value: 0.06111423298716545.\n",
      "on end of epoch#126: start annealing from 0.0001 to 1e-05\n",
      "Better model found at epoch 128 with valid_loss value: 0.06109122186899185.\n",
      "Better model found at epoch 129 with valid_loss value: 0.06084493547677994.\n",
      "Better model found at epoch 132 with valid_loss value: 0.06079511716961861.\n",
      "Better model found at epoch 134 with valid_loss value: 0.06072667986154556.\n",
      "Better model found at epoch 139 with valid_loss value: 0.06011078506708145.\n",
      "Better model found at epoch 153 with valid_loss value: 0.05920783802866936.\n",
      "Better model found at epoch 154 with valid_loss value: 0.05919027328491211.\n",
      "Better model found at epoch 169 with valid_loss value: 0.058980751782655716.\n",
      "on end of epoch#171: start annealing from 1e-05 to 1.0000000000000002e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "multi_train(get_learn=partial(resnet_unet.get_learn,data=data), \n",
    "            epoch_len=1e9, epochs=500,\n",
    "            opts=opts, lrs=lrs, checkpoints=checkpoints,\n",
    "            tb_log_root='./tb_log/',\n",
    "            autoSave=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted train_script_logger.ipynb to ../train_script_logger.py\r\n"
     ]
    }
   ],
   "source": [
    "!python ../notebook2script.py --fname 'train_script_logger.ipynb' --outputDir '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
