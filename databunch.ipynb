{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_y(x, ds_rootdir, imgdir, maskdir):\n",
    "    yfn = os.path.join(ds_rootdir, maskdir, '%s_mask%s' % (x.stem, x.suffix))\n",
    "    #print(yfn, x.stem, x.suffix)\n",
    "    return yfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def imgp_CLAHE(pil_img):\n",
    "    '''\n",
    "    对图片进行限制对比度自适应直方图均衡化\n",
    "    '''\n",
    "    img = cv2.cvtColor(np.asarray(pil_img),cv2.COLOR_RGB2BGR)\n",
    "    #print(img.shape)\n",
    "    clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8,8))\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hsv[:, :, 2] = clahe.apply(hsv[:, :, 2])\n",
    "    img2 = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    ret = PIL.Image.fromarray(cv2.cvtColor(img2,cv2.COLOR_BGR2RGB))\n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def custom_split_et(data, valid_pct = 0.2, img_dir = '', val_et_not_in_train = True):\n",
    "    '''\n",
    "    自定义分割验证集和训练集。这个是针对带有elastic transform生成的数据集的。\n",
    "    保证带有变换的图片没有放在验证集里面。\n",
    "    同时验证集里面图片对应的带变换的图片也没在训练集里面，也就是被丢弃了(val_et_not_in_train = True)。\n",
    "    所以数据总数会可能会少于图片数量(val_et_not_in_train = True的情况下)。\n",
    "    带变换图片的文件名格式是 原始图片文件名+ '_et' + 扩展名\n",
    "    使用的时候用partial指定valid_pct和img_dir两个参数。   \n",
    "    参数:\n",
    "        data:ItemLists\n",
    "        valid_pct：验证集占比\n",
    "        img_dir：图片存放路径\n",
    "        val_et_not_in_train：验证集里面图片对应的带变换的图片也没在训练集里面.\n",
    "    返回值：\n",
    "        分割后的ItemLists\n",
    "    '''\n",
    "    #import pdb; pdb.set_trace()\n",
    "    assert len(data.items) > 0, '空数据集?'\n",
    "    fns = [o.name for o in os.scandir(img_dir) if o.is_file()]\n",
    "    #取出所有的不带_et的文件名。也就是正常的图片\n",
    "    fns = [i for i in fns if i.find('_et') < 0]\n",
    "    random.shuffle(fns)\n",
    "    spidx = int(len(fns) * valid_pct)\n",
    "    #验证集和训练集的正常图片列表\n",
    "    vals = fns[:spidx]\n",
    "    trains = fns[spidx:]\n",
    "    #把那些正常图片对应的变形图片加进来到训练集里面。验证集对应的变形图片丢弃\n",
    "    trains += [o.replace('.', '_et.') for o in trains]\n",
    "    if not val_et_not_in_train:\n",
    "        trains += [o.replace('.', '_et.') for o in vals]\n",
    "    #生成完整的带路径的图片列表\n",
    "    valsfp = [os.path.join(img_dir, o) for o in vals]\n",
    "    trainsfp = [os.path.join(img_dir, o) for o in trains]\n",
    "    #生成每个图片对应的在data.items里面的index记录\n",
    "    #只记录文件名不包括目录名。调用的时候参数带'./'会影响到查找\n",
    "    sitems = [str(o).split('/')[-1] for o in data.items]    \n",
    "    tr_idxs = [sitems.index(o.split('/')[-1]) for o in trainsfp]\n",
    "    val_idxs = [sitems.index(o.split('/')[-1]) for o in valsfp]\n",
    "    assert -1 not in tr_idxs\n",
    "    assert -1 not in val_idxs\n",
    "    for i in val_idxs:\n",
    "        if i in tr_idxs:\n",
    "            assert False\n",
    "    return data.split_by_idxs(tr_idxs, val_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_databunch(ds_root_dir = 'dataset_20200708', ds_imgdir = 'image'\n",
    "                  , ds_maskdir = 'mask', bs = 16, valid_pct = 0.2\n",
    "                  , device = torch.device('cuda')\n",
    "                  , transforms = get_transforms(max_zoom = 1.)\n",
    "                  , img_processor = []\n",
    "                  , custom_split = None):\n",
    "    '''\n",
    "    获取databunch\n",
    "    参数：\n",
    "        ds_root_dir：数据集的根目录\n",
    "        ds_imgdir：图片子目录\n",
    "        ds_maskdir: mask图片子目录\n",
    "        bs：batch_size\n",
    "        valid_pct:验证集百分比\n",
    "        device: 设备\n",
    "        transforms: 无缩放，其余默认参数。\n",
    "        img_process: 图片处理。取值范围：\n",
    "            'CLAHE': 比度自适应直方图均衡化\n",
    "        custom_split: 自定义的split方式\n",
    "                    现在主要是给带有elastic transform的数据集用\n",
    "                    ，保证变形的图片没有分在验证集\n",
    "                    ，并且验证集里面的对应的变形图片也没在训练集里面\n",
    "    返回值：\n",
    "        databunch\n",
    "    '''\n",
    "    def imgp_afteropen(pil_img, img_processor):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        ret = pil_img\n",
    "        for imgp in img_processor:\n",
    "            if 'CLAHE' == imgp:\n",
    "                ret = imgp_CLAHE(ret)\n",
    "            else:\n",
    "                assert False, '没有实现'\n",
    "        return ret\n",
    "    \n",
    "    img_processor_func = None\n",
    "    if img_processor is not None and len(img_processor) > 0:\n",
    "        img_processor_func = partial(imgp_afteropen, img_processor = img_processor)\n",
    "        \n",
    "    #import pdb; pdb.set_trace()\n",
    "    data = SegmentationItemList.from_folder(os.path.join(ds_root_dir, ds_imgdir)\n",
    "                , after_open = img_processor_func)\n",
    "    \n",
    "    if custom_split is None:\n",
    "        data = data.split_by_rand_pct(valid_pct)\n",
    "    else:\n",
    "        data = custom_split(data)\n",
    "        \n",
    "    data = data.label_from_func( \\\n",
    "            partial(get_y, ds_rootdir = ds_root_dir, imgdir = ds_imgdir, maskdir = ds_maskdir) \\\n",
    "            , classes=['bg', 'water'])\n",
    "    \n",
    "    #import pdb; pdb.set_trace()\n",
    "    if transforms is not None:\n",
    "        data = data.transform(transforms, tfm_y = True)\n",
    "    data = data.databunch(bs=bs, num_workers = 0, device = device)\n",
    "    data = data.normalize(imagenet_stats)\n",
    "    \n",
    "    return data\n",
    "\n",
    "#data = get_databunch(bs = 4)\n",
    "#data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_databunch_et(ds_root_dir = 'dataset_20200708', ds_imgdir = 'image'\n",
    "          , ds_maskdir = 'mask', bs = 16, valid_pct = 0.2\n",
    "          , device = torch.device('cuda')\n",
    "          , transforms = get_transforms(max_zoom = 1.)\n",
    "          , img_processor = []):\n",
    "    '''\n",
    "    对get_databunch和custom_split调用的包装\n",
    "    '''\n",
    "    custom_split = partial(custom_split_et\n",
    "                    , img_dir = os.path.join(ds_root_dir, ds_imgdir)\n",
    "                    , valid_pct = 0.2)\n",
    "    return get_databunch(ds_root_dir = ds_root_dir, ds_imgdir = ds_imgdir\n",
    "                    , ds_maskdir = ds_maskdir, bs = bs, valid_pct = valid_pct\n",
    "                    , device = device, transforms = transforms\n",
    "                    , img_processor = img_processor\n",
    "                    , custom_split = custom_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_databunch(bs = 4, device = device\n",
    "        , ds_root_dir = 'label/dataset_20200713')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#限制对比度自适应直方图均衡化\n",
    "data = get_databunch(bs = 4, device = device, transforms = None\n",
    "        , ds_root_dir = 'label/dataset_20200713', img_processor = ['CLAHE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.show_batch(ds_type=DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#带elastic transform的.一共400图像，验证集里面带变换的被丢弃，所以一共360张图像\n",
    "data = get_databunch_et(bs = 16, device = device\n",
    "        , ds_root_dir = 'data/dataset_20200715_200_et')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (320 items)\n",
       "x: SegmentationItemList\n",
       "Image (3, 512, 512),Image (3, 512, 512),Image (3, 512, 512),Image (3, 512, 512),Image (3, 512, 512)\n",
       "y: SegmentationLabelList\n",
       "ImageSegment (1, 512, 512),ImageSegment (1, 512, 512),ImageSegment (1, 512, 512),ImageSegment (1, 512, 512),ImageSegment (1, 512, 512)\n",
       "Path: data/dataset_20200715_200_et/image;\n",
       "\n",
       "Valid: LabelList (40 items)\n",
       "x: SegmentationItemList\n",
       "Image (3, 512, 512),Image (3, 512, 512),Image (3, 512, 512),Image (3, 512, 512),Image (3, 512, 512)\n",
       "y: SegmentationLabelList\n",
       "ImageSegment (1, 512, 512),ImageSegment (1, 512, 512),ImageSegment (1, 512, 512),ImageSegment (1, 512, 512),ImageSegment (1, 512, 512)\n",
       "Path: data/dataset_20200715_200_et/image;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#统计一下空白图片数量\n",
    "empt = 0\n",
    "for i in range(len(data.valid_ds)):\n",
    "    na = data.valid_ds[i][1].data.numpy()\n",
    "    na[na < 1] = 0\n",
    "    na[na >= 1] = 1\n",
    "    #print(na.sum(), na.sum() / 512 / 512)\n",
    "    #data.train_ds[idx][1]\n",
    "    if na.sum() / 512 / 512 < 0.04:\n",
    "        empt += 1\n",
    "        print('empt', empt, i, na.sum(), na.sum() / 512 / 512)\n",
    "print(empt / len(data.valid_ds))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted databunch.ipynb to exp/nb_databunch.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py --fname 'databunch.ipynb' --outputDir './exp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
